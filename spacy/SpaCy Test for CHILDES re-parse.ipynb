{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import childespy\n",
    "#python -m spacy download en_core_web_lg in the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_extraction(obj, nlp):    \n",
    "    if isinstance(obj, str):\n",
    "        utt_str = obj        \n",
    "    elif isinstance(obj, dict):\n",
    "        utt_str = obj['gloss_with_punct']\n",
    "\n",
    "    doc = nlp(utt_str)\n",
    "    rdf = pd.DataFrame([{'text':token.text, 'lemma':token.lemma_, 'pos':token.pos_, 'tag':\n",
    "              token.tag_, 'dependency':token.dep_,\n",
    "                'morph':token.morph} for token in doc])    \n",
    "    \n",
    "    if isinstance(obj, str):\n",
    "        return(rdf)\n",
    "    elif isinstance(obj, dict):\n",
    "        rdf['utterance_id'] = obj['id']\n",
    "        rdf['speaker_code'] = obj['speaker_code']        \n",
    "        return(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dependency</th>\n",
       "      <th>morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WP</td>\n",
       "      <td>dobj</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>does</td>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>aux</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>(Definite=Def, PronType=Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bus</td>\n",
       "      <td>bus</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>driver</td>\n",
       "      <td>driver</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>say</td>\n",
       "      <td>say</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>(VerbForm=Inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>(PunctType=Peri)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text   lemma    pos  tag dependency  \\\n",
       "0    what    what   PRON   WP       dobj   \n",
       "1    does      do    AUX  VBZ        aux   \n",
       "2     the     the    DET   DT        det   \n",
       "3     bus     bus   NOUN   NN   compound   \n",
       "4  driver  driver   NOUN   NN      nsubj   \n",
       "5     say     say   VERB   VB       ROOT   \n",
       "6       ?       ?  PUNCT    .      punct   \n",
       "\n",
       "                                               morph  \n",
       "0                                                 ()  \n",
       "1  (Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...  \n",
       "2                       (Definite=Def, PronType=Art)  \n",
       "3                                      (Number=Sing)  \n",
       "4                                      (Number=Sing)  \n",
       "5                                     (VerbForm=Inf)  \n",
       "6                                   (PunctType=Peri)  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_extraction('what does the bus driver say?', en_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SpaCy on Providence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvd_idx = childespy.get_sql_query('select * from corpus where name = \"Providence\"').iloc[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pvd_utts = childespy.get_sql_query('select * from utterance where corpus_id = '+str(pvd_idx) ,\n",
    "#         db_version = \"2020.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_transcript_id = 42204\n",
    "\n",
    "pvd_utts = childespy.get_sql_query('select * from utterance where transcript_id = '+str(selected_transcript_id) ,\n",
    "db_version = \"2020.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gloss', 'stem', 'actual_phonology', 'model_phonology', 'type',\n",
       "       'language', 'num_morphemes', 'num_tokens', 'utterance_order',\n",
       "       'corpus_name', 'part_of_speech', 'speaker_code', 'speaker_name',\n",
       "       'speaker_role', 'target_child_name', 'target_child_age',\n",
       "       'target_child_sex', 'media_start', 'media_end', 'media_unit',\n",
       "       'collection_name', 'collection_id', 'corpus_id', 'speaker_id',\n",
       "       'target_child_id', 'transcript_id', 'punct', 'gloss_with_punct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvd_utts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_gloss(gloss):\n",
    "    # migt be better to split these glosses (black+bird -> black bird),but then we lose the alignment \n",
    "    return(str(gloss).replace('+','').replace('_',''))\n",
    "pvd_utts.gloss = [fix_gloss(x) for x in pvd_utts.gloss]\n",
    "\n",
    "# add back punctuation from the utterance type\n",
    "punct_for_type = {\n",
    "    'question':'?',\n",
    "    'declarative':'.',\n",
    "    'self interruption':'.',\n",
    "    'interruption':'!',\n",
    "    'trail off':'...',\n",
    "    'interruption question':'?',\n",
    "    'trail off question':'?',\n",
    "    'imperative_emphatic':'!' \n",
    "}\n",
    "pvd_utts['punct'] = [punct_for_type[x] if x in punct_for_type else '.'\n",
    "                        for x in pvd_utts.type ]\n",
    "\n",
    "# add the speaker code (for compatibility with a fine-tuned model that has speaker identity)\n",
    "pvd_utts = pvd_utts.loc[[x is not None for x in pvd_utts.punct]]\n",
    "\n",
    "\n",
    "# build a single form that is appropriate for running through the tokenizer\n",
    "pvd_utts['gloss_with_punct'] = [x['gloss'] + x['punct'] for x in pvd_utts.to_dict('records')] \n",
    "pvd_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>stem</th>\n",
       "      <th>actual_phonology</th>\n",
       "      <th>model_phonology</th>\n",
       "      <th>type</th>\n",
       "      <th>language</th>\n",
       "      <th>num_morphemes</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>utterance_order</th>\n",
       "      <th>...</th>\n",
       "      <th>media_end</th>\n",
       "      <th>media_unit</th>\n",
       "      <th>collection_name</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>target_child_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>punct</th>\n",
       "      <th>gloss_with_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16759250</td>\n",
       "      <td>where do you want me to go</td>\n",
       "      <td>where do you want me to go</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.830</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22708</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>?</td>\n",
       "      <td>where do you want me to go?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16759261</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere</td>\n",
       "      <td>anywhere you feel comfort anywhere</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>.</td>\n",
       "      <td>anywhere you'll feel comfortable um anywhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16759270</td>\n",
       "      <td>please don't do that</td>\n",
       "      <td>please do do that</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.888</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>.</td>\n",
       "      <td>please don't do that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16759279</td>\n",
       "      <td>this is</td>\n",
       "      <td>this be</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>self interruption</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>15.525</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>.</td>\n",
       "      <td>this is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16759300</td>\n",
       "      <td>go into the kitchen and check in about</td>\n",
       "      <td>go into the kitchen and check in about</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>self interruption</td>\n",
       "      <td>eng</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22708</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>.</td>\n",
       "      <td>go into the kitchen and check in about.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>16769439</td>\n",
       "      <td>god bless you</td>\n",
       "      <td>god bless you</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>718</td>\n",
       "      <td>...</td>\n",
       "      <td>3317.463</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>.</td>\n",
       "      <td>god bless you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>16769460</td>\n",
       "      <td>thank you</td>\n",
       "      <td>thank you</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>719</td>\n",
       "      <td>...</td>\n",
       "      <td>3338.480</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>.</td>\n",
       "      <td>thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>16769486</td>\n",
       "      <td>thank you</td>\n",
       "      <td>thank you</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>declarative</td>\n",
       "      <td>eng</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>...</td>\n",
       "      <td>3347.488</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>.</td>\n",
       "      <td>thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>16769509</td>\n",
       "      <td>Alex where's your big truck</td>\n",
       "      <td>Alex where your big truck</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>721</td>\n",
       "      <td>...</td>\n",
       "      <td>3358.255</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>?</td>\n",
       "      <td>Alex where's your big truck?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>16769529</td>\n",
       "      <td>where's your big truck with all the blocks in it</td>\n",
       "      <td>where your big truck with all the block in it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>question</td>\n",
       "      <td>eng</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>3361.831</td>\n",
       "      <td>s</td>\n",
       "      <td>Eng-NA</td>\n",
       "      <td>21</td>\n",
       "      <td>328</td>\n",
       "      <td>22707</td>\n",
       "      <td>22704</td>\n",
       "      <td>42204</td>\n",
       "      <td>?</td>\n",
       "      <td>where's your big truck with all the blocks in it?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             gloss  \\\n",
       "1    16759250                        where do you want me to go   \n",
       "2    16759261      anywhere you'll feel comfortable um anywhere   \n",
       "3    16759270                              please don't do that   \n",
       "4    16759279                                           this is   \n",
       "5    16759300            go into the kitchen and check in about   \n",
       "..        ...                                               ...   \n",
       "718  16769439                                     god bless you   \n",
       "719  16769460                                         thank you   \n",
       "720  16769486                                         thank you   \n",
       "721  16769509                       Alex where's your big truck   \n",
       "722  16769529  where's your big truck with all the blocks in it   \n",
       "\n",
       "                                              stem actual_phonology  \\\n",
       "1                       where do you want me to go                    \n",
       "2               anywhere you feel comfort anywhere                    \n",
       "3                                please do do that                    \n",
       "4                                          this be                    \n",
       "5           go into the kitchen and check in about                    \n",
       "..                                             ...              ...   \n",
       "718                                  god bless you                    \n",
       "719                                      thank you                    \n",
       "720                                      thank you                    \n",
       "721                      Alex where your big truck                    \n",
       "722  where your big truck with all the block in it                    \n",
       "\n",
       "    model_phonology               type language  num_morphemes  num_tokens  \\\n",
       "1                             question      eng              7           7   \n",
       "2                          declarative      eng              8           6   \n",
       "3                          declarative      eng              5           4   \n",
       "4                    self interruption      eng              3           2   \n",
       "5                    self interruption      eng              8           8   \n",
       "..              ...                ...      ...            ...         ...   \n",
       "718                        declarative      eng              3           3   \n",
       "719                        declarative      eng              2           2   \n",
       "720                        declarative      eng              2           2   \n",
       "721                           question      eng              6           5   \n",
       "722                           question      eng             12          10   \n",
       "\n",
       "     utterance_order  ... media_end media_unit collection_name collection_id  \\\n",
       "1                  1  ...     7.830          s          Eng-NA            21   \n",
       "2                  2  ...       NaN       None          Eng-NA            21   \n",
       "3                  3  ...    10.888          s          Eng-NA            21   \n",
       "4                  4  ...    15.525          s          Eng-NA            21   \n",
       "5                  5  ...       NaN       None          Eng-NA            21   \n",
       "..               ...  ...       ...        ...             ...           ...   \n",
       "718              718  ...  3317.463          s          Eng-NA            21   \n",
       "719              719  ...  3338.480          s          Eng-NA            21   \n",
       "720              720  ...  3347.488          s          Eng-NA            21   \n",
       "721              721  ...  3358.255          s          Eng-NA            21   \n",
       "722              722  ...  3361.831          s          Eng-NA            21   \n",
       "\n",
       "    corpus_id speaker_id  target_child_id transcript_id  punct  \\\n",
       "1         328      22708            22704         42204      ?   \n",
       "2         328      22707            22704         42204      .   \n",
       "3         328      22707            22704         42204      .   \n",
       "4         328      22707            22704         42204      .   \n",
       "5         328      22708            22704         42204      .   \n",
       "..        ...        ...              ...           ...    ...   \n",
       "718       328      22707            22704         42204      .   \n",
       "719       328      22707            22704         42204      .   \n",
       "720       328      22707            22704         42204      .   \n",
       "721       328      22707            22704         42204      ?   \n",
       "722       328      22707            22704         42204      ?   \n",
       "\n",
       "                                      gloss_with_punct  \n",
       "1                          where do you want me to go?  \n",
       "2        anywhere you'll feel comfortable um anywhere.  \n",
       "3                                please don't do that.  \n",
       "4                                             this is.  \n",
       "5              go into the kitchen and check in about.  \n",
       "..                                                 ...  \n",
       "718                                     god bless you.  \n",
       "719                                         thank you.  \n",
       "720                                         thank you.  \n",
       "721                       Alex where's your big truck?  \n",
       "722  where's your big truck with all the blocks in it?  \n",
       "\n",
       "[722 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvd_utts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_examples = pd.concat([spacy_extraction(x, en_nlp) for x in pvd_utts.to_dict('records')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_examples.to_csv('Providence_42204_spacy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SpaCy on Lyon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using supported database version: '2020.1'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_transcript_id = 44629\n",
    "\n",
    "lyon_utts = childespy.get_sql_query('select * from utterance where transcript_id = '+str(selected_transcript_id) ,\n",
    "db_version = \"2020.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 29)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyon_utts.gloss = [fix_gloss(x) for x in lyon_utts.gloss]\n",
    "\n",
    "# add back punctuation from the utterance type\n",
    "punct_for_type = {\n",
    "    'question':'?',\n",
    "    'declarative':'.',\n",
    "    'self interruption':'.',\n",
    "    'interruption':'!',\n",
    "    'trail off':'...',\n",
    "    'interruption question':'?',\n",
    "    'trail off question':'?',\n",
    "    'imperative_emphatic':'!' \n",
    "}\n",
    "lyon_utts['punct'] = [punct_for_type[x] if x in punct_for_type else '.'\n",
    "                        for x in lyon_utts.type ]\n",
    "\n",
    "# add the speaker code (for compatibility with a fine-tuned model that has speaker identity)\n",
    "lyon_utts = lyon_utts.loc[[x is not None for x in lyon_utts.punct]]\n",
    "\n",
    "\n",
    "# build a single form that is appropriate for running through the tokenizer\n",
    "lyon_utts['gloss_with_punct'] = [x['gloss'] + x['punct'] for x in lyon_utts.to_dict('records')] \n",
    "lyon_utts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyon_examples = pd.concat([spacy_extraction(x, fr_nlp) for x in lyon_utts.to_dict('records')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyon_examples.to_csv('Lyon_44629_spacy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Information is Present in SpaCy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = 'what do the bus drivers say?'\n",
    "test_spacy = en_nlp(test_str)\n",
    "dir(test_spacy[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number=Plur"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_spacy[4].morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tense=Pres|VerbForm=Fin"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_spacy[5].morph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "childes-db-python3.7",
   "language": "python",
   "name": "childes-db-python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
