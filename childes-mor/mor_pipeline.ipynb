{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd049c8-8131-4b7d-b21e-445d224d8e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pdb\n",
    "\n",
    "# xml namespace\n",
    "ns = {'': 'http://www.talkbank.org/ns/talkbank'}\n",
    "ns_tag = lambda tag: '{' + ns[''] + '}' + tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3547cb1c-d1a7-4152-a94a-b8e908c3efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcript(transcript_file):\n",
    "    transcript = open(transcript_file).read()\n",
    "    transcript = re.sub('</?[ps]?g>', '', transcript) # get rid of groups (g, pg, sg)\n",
    "    return(et.fromstring(transcript))\n",
    "    \n",
    "def process_transcript(transcript_file, df_w, df_mor, df_mk, verbose = False):\n",
    "    t = load_transcript(transcript_file)\n",
    "    for u_index, u in enumerate(t.findall('./u', ns)):\n",
    "        df_w, df_mor, df_mk = process_utterance(u, u_index, df_w, df_mor, df_mk, verbose)\n",
    "                \n",
    "    df_w = pd.DataFrame(df_w)\n",
    "    df_mor = pd.DataFrame(df_mor)\n",
    "    df_mk = pd.DataFrame(df_mk)\n",
    "        \n",
    "    df_w['transcript'] = transcript_file\n",
    "    df_mor['transcript'] = transcript_file\n",
    "    df_mk['transcript'] = transcript_file\n",
    "    return(df_w, df_mor, df_mk)\n",
    "\n",
    "def process_utterance(u, u_index, df_w, df_mor, df_mk, verbose = False):\n",
    "    if verbose: print('utterance', u_index)\n",
    "\n",
    "    # find all nodes in utterance that have tag w or tagMarker\n",
    "    w_tags = [ns_tag(tag) for tag in ['w', 'tagMarker']]\n",
    "    u_parts = [p for p in u.findall(\"./\", ns) if p.tag in w_tags]\n",
    "\n",
    "    for p in u_parts:\n",
    "        # tagMarkers don't go in df_w, only df_mor\n",
    "        if p.tag == ns_tag(\"tagMarker\"):\n",
    "            mor = p.find('./mor', ns)\n",
    "            if mor is not None:\n",
    "                df_mor, df_mk = process_mor(mor = mor, mor_index = len(df_mor),\n",
    "                                            clitic_type = None,\n",
    "                                            is_separated_prefix = False,\n",
    "                                            u_id = u_index, w_id = None, df_mor = df_mor, df_mk = df_mk)\n",
    "        else:\n",
    "            df_w, df_mor, df_mk = process_word(p, len(df_w), u_index, df_w, df_mor, df_mk)\n",
    "            \n",
    "    return(df_w, df_mor, df_mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fd9969-5464-416c-b9a0-a9d85aae8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_gloss(w):\n",
    "    # construct word string out of text, compound parts, internal shortenings\n",
    "    w_tags = [ns_tag(tag) for tag in ['shortening', 'wk']]\n",
    "    w_parts = [p for p in w.findall(\"./\", ns) if p.tag in w_tags]\n",
    "    word = w.text or \"\"\n",
    "    has_compound, has_clitic, has_shortening = False, False, False\n",
    "    for p in w_parts:\n",
    "        if p.get('type') == 'cmp': # compound\n",
    "            word = word + '+' + (p.tail or \"\")\n",
    "            has_compound = True\n",
    "        elif p.get('type') == 'cli': # clitic\n",
    "            word = word + '~' + (p.tail or \"\")\n",
    "            has_clitic = True\n",
    "        elif p.tag == ns_tag('shortening'): # shortening\n",
    "            word = word + '(' + p.text + ')' + (p.tail or \"\")\n",
    "            has_shortening = True\n",
    "        else:\n",
    "            raise ValueError('unknown component inside word')\n",
    "    return(word, has_compound, has_clitic, has_shortening)\n",
    "\n",
    "def process_word(w, w_index, u_id, df_w, df_mor, df_mk, verbose = False):\n",
    "\n",
    "    gloss, has_compound, has_clitic, has_shortening = construct_gloss(w)\n",
    "    \n",
    "    words = [w]\n",
    "    # replacements contain 1 or more words\n",
    "    rep_words = w.findall('./replacement/w', ns)\n",
    "    if len(rep_words):\n",
    "        # treat multiple words in replacement as a linkage (except separated prefix)\n",
    "        rep_glosses = [construct_gloss(rep)[0] for rep in rep_words]\n",
    "        if rep_words[0].get('separated-prefix') == 'true':\n",
    "            rep_gloss = rep_glosses[0] + ' ' + \"_\".join(rep_glosses[1:])\n",
    "        else:\n",
    "            rep_gloss = \"_\".join(rep_glosses)\n",
    "        # mor tag can be child of w within replacement or after replacement\n",
    "        words += rep_words\n",
    "    else:\n",
    "        rep_gloss = None\n",
    "    \n",
    "    if verbose: print(\"\\t\", gloss)\n",
    "    w_data = {\n",
    "        'id': w_index,\n",
    "        'u_fk': u_id,\n",
    "        'gloss': gloss,\n",
    "        'replacement': rep_gloss,\n",
    "        'pos': w.get('pos'),\n",
    "        'form_marker': w.get('formType'), # @x\n",
    "        'form_marker_suffix': w.get('formSuffix'), # @x-s\n",
    "        'incomplete_type': w.get('type'), # omission, fragment, filler, incomplete\n",
    "        'unidentifiable_type': w.get('untranscribed'), # unintelligible, unintelligible-with-pho, untranscribed\n",
    "        'has_compound': has_compound,\n",
    "        'has_clitic': has_clitic,\n",
    "        'has_shortening' : has_shortening\n",
    "    }\n",
    "    df_w.append(w_data)\n",
    "\n",
    "    for wo in words:\n",
    "        is_separated_prefix = wo.get('separated-prefix') == 'true'\n",
    "\n",
    "        # 0 or 1 mor, only type mor (i.e. not training)\n",
    "        mor = wo.findall('./mor[@type=\"mor\"]', ns)\n",
    "        assert len(mor) <= 1\n",
    "        if len(mor):\n",
    "            mor = mor[0]\n",
    "            df_mor, df_mk = process_mor(mor = mor, mor_index = len(df_mor), clitic_type = None,\n",
    "                                        is_separated_prefix = is_separated_prefix,\n",
    "                                        u_id = u_id, w_id = w_index, df_mor = df_mor, df_mk = df_mk)\n",
    "\n",
    "            # 0 or 1 or multiple mor-pre or mor-post (clitics)\n",
    "            clitics = mor.findall('./mor-pre', ns) + mor.findall('./mor-post', ns)\n",
    "            if clitics is not None:\n",
    "                for mor_index, clitic in enumerate(clitics, start = 1):\n",
    "                    clitic_type = re.search(\"-(.*?)$\", clitic.tag).group(1)\n",
    "                    df_mor, df_mk = process_mor(mor = clitic, mor_index = len(df_mor) + mor_index,\n",
    "                                                clitic_type = clitic_type, is_separated_prefix = is_separated_prefix,\n",
    "                                                u_id = u_id, w_id = w_index, df_mor = df_mor, df_mk = df_mk)\n",
    "    \n",
    "    return(df_w, df_mor, df_mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a942ea-e16e-4a67-9e67-b18579de28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mor(mor, mor_index, clitic_type, is_separated_prefix, u_id, w_id, df_mor, df_mk):\n",
    "    \n",
    "    # expect 0 or 1 of each of these tags\n",
    "    assert len(mor.findall('./mw', ns)) <= 1\n",
    "    assert len(mor.findall('./mwc', ns)) <= 1\n",
    "    assert len(mor.findall('./gra', ns)) <= 1\n",
    "    assert len(mor.findall('./mw/pos', ns)) <= 1\n",
    "    assert len(mor.findall('./mw/pos/c', ns)) <= 1\n",
    "    assert len(mor.findall('./mw/stem', ns)) <= 1\n",
    "\n",
    "    # mw is inside mwc for compounds\n",
    "    # TODO: mwc has a pos and unbounded mpfx\n",
    "    mwc = mor.find('./mwc', ns)\n",
    "    mws = mor.findall('./mw', ns) if mwc is None else mwc.findall('./mw', ns)\n",
    "    is_compound = mwc is not None\n",
    "    \n",
    "    # 0 or 1 or multiple menx (multiples separated by /)\n",
    "    menxs = mor.findall('./menx', ns)\n",
    "    menx = \"/\".join([menx.text for menx in menxs]) if menxs is not None else None\n",
    "    \n",
    "    # 0 or 1 gra\n",
    "    gra = mor.findall('./gra[@type=\"gra\"]', ns)\n",
    "    assert len(gra) <= 1\n",
    "    if len(gra):\n",
    "        gra = gra[0]\n",
    "        gra_index, gra_head, gra_relation = gra.get('index'), gra.get('head'), gra.get('relation')\n",
    "    else:\n",
    "        gra_index, gra_head, gra_relation = None, None, None\n",
    "    \n",
    "    for mw in mws:\n",
    "        pos_c = mw.find('./pos/c', ns)\n",
    "        pos_s = mw.findall('./pos/s', ns)\n",
    "        pos = \":\".join([pos_c.text] + [s.text for s in pos_s if s is not None])\n",
    "        mor_data = {\n",
    "            'id': mor_index,\n",
    "            'u_fk': u_id,\n",
    "            'w_fk': w_id,\n",
    "            'is_compound': is_compound,\n",
    "            'clitic_type': clitic_type,\n",
    "            'is_separated_prefix': is_separated_prefix,\n",
    "            'pos': pos,\n",
    "            'stem': mw.find('./stem', ns).text,\n",
    "            'english': menx,\n",
    "            'gra_index': gra_index,\n",
    "            'gra_head': gra_head,\n",
    "            'gra_relation': gra_relation\n",
    "        }\n",
    "        df_mor.append(mor_data)\n",
    "        \n",
    "        df_mk = process_mw(mw, mor_index, df_mk)\n",
    "        \n",
    "    return(df_mor, df_mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5cc4ed4-d00a-44f7-a12f-a2be430e315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mw(mw, mor_id, df_mk):\n",
    "    \n",
    "    # prefixes\n",
    "    for mpfx in mw.findall('./mpfx', ns):\n",
    "        mpfx_data = {\n",
    "            'id': len(df_mk),\n",
    "            'mor_fk': mor_id,\n",
    "            'affix': mpfx.text,\n",
    "            'affix_type': 'prefix'\n",
    "        }\n",
    "        df_mk.append(mpfx_data)\n",
    "        \n",
    "    # suffixes\n",
    "    for mk in mw.findall('./mk', ns):\n",
    "        mk_data = {\n",
    "            'id': len(df_mk),            \n",
    "            'mor_fk': mor_id,\n",
    "            'affix': mk.text,\n",
    "            'affix_type': mk.get('type')\n",
    "        }\n",
    "        df_mk.append(mk_data)\n",
    "        \n",
    "    return(df_mk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c5d5d1d1-3cfb-4c71-b467-07d21eb127c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transcript_file = \"/Users/mikabr/childes/childes/Spanish/OreaPine/Juan/020317.xml\"\n",
    "# t_df_w, t_df_mor, t_df_mk = process_transcript(transcript_file, list(), list(), list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0f453e-6cad-4015-9b0e-a7c2c67679e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_dir(corpus_dir):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(corpus_dir):\n",
    "        print(dirpath)\n",
    "        dirnames.sort()\n",
    "        files = [os.path.join(dirpath, file) for file in sorted(filenames) if os.path.splitext(file)[1] == '.xml']\n",
    "        if len(files):\n",
    "            dir_df_w, dir_df_mor, dir_df_mk = list(), list(), list()\n",
    "            for file in files:\n",
    "                tra_df_w, tra_df_mor, tra_df_mk = process_transcript(file, list(), list(), list())\n",
    "                dir_df_w.append(tra_df_w.copy())\n",
    "                dir_df_mor.append(tra_df_mor.copy())\n",
    "                dir_df_mk.append(tra_df_mk.copy())\n",
    "            pd.concat(dir_df_w).to_csv(os.path.join(dirpath, \"w.csv\"))\n",
    "            pd.concat(dir_df_mor).to_csv(os.path.join(dirpath, \"mor.csv\"))\n",
    "            pd.concat(dir_df_mk).to_csv(os.path.join(dirpath, \"mk.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56bf4f9a-b5f9-45f4-82c9-09babcbb52e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_dir(\"/Users/mikabr/childes/phonbank\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
